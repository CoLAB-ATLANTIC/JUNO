{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ea754af",
   "metadata": {},
   "source": [
    "#### In this notebook is presented a pipeline for the aplication of the Cayula-Cornillon Single Image Edge Detector (SIED) algorithm. This algorithm receives SST data for a specific day for a given coordinate pair and applies the Cayula-Cornillon algorithm to just that image.  The data must be provided in a dataframe form where 1 column is related to the longitude values, another is related to the latitude values and finally the last one has SST values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2bb9c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77271647",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import netCDF4 as nc\n",
    "import xarray as xr\n",
    "import os\n",
    "from pathlib import Path\n",
    "from numpy import nanmedian\n",
    "import cv2\n",
    "import scipy\n",
    "import scipy.signal\n",
    "import math\n",
    "from numpy.fft import fft2\n",
    "import cmocean\n",
    "import matplotlib\n",
    "from matplotlib.colors import ListedColormap\n",
    "plt.rcParams[\"figure.figsize\"] = 12, 10\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb704adb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94dce45d",
   "metadata": {},
   "source": [
    "## Import Data\n",
    "\n",
    "\n",
    "In the data directory there are several netCDF files with MUR and Reanalysis data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c68db5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function to get our netCDF file that is stored in the data directory and convert it to a dataframe.\n",
    "    The data parameter is the string name of the netCDF file we want to import\n",
    "    \"\"\"\n",
    "    \n",
    "    current_path = os.getcwd()\n",
    "    data_folder = os.path.join(current_path,\"../data\")\n",
    "    \n",
    "    nc_path = os.path.join(data_folder, data)\n",
    "    ds = nc.Dataset(nc_path)\n",
    "    netCDF = xr.load_dataset(nc_path)\n",
    "    \n",
    "    df = netCDF.to_dataframe()\n",
    "    df = df.reset_index()\n",
    "    \n",
    "    df = df.drop(['depth'], axis=1, errors='ignore') #drop the column 'depth' if exists: only exists in reanalysis\n",
    "    \n",
    "    #if we are importing MUR data, rename columns and convert temperature celsius\n",
    "    if data.startswith('mur'):\n",
    "        df.rename(columns={'lat': 'latitude', 'lon': 'longitude', 'time': 'time', 'analysed_sst':'thetao'}, inplace=True)\n",
    "        df['thetao'] = df['thetao']-273.15   \n",
    "        \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48848173",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the netCDF of MUR data from August 2019 and convert it to a dataframe\n",
    "df_mur_aug = get_data('murAugust2019.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef13ce2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframe with data from 1st August 2019 for the MUR data\n",
    "Aug1_mur = df_mur_aug[df_mur_aug['time'] == '2019-08-01 09:00:00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a94554b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a3bffa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02718a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "yesterday = get_data('sst_20220615.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8bb9ed87",
   "metadata": {},
   "outputs": [],
   "source": [
    "yesterday.rename(columns={'lat': 'latitude', 'lon': 'longitude', 'time': 'time', 'analysed_sst':'thetao'}, inplace=True)\n",
    "yesterday['thetao'] = yesterday['thetao']-273.15   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c28130",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1881c1d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cc39be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cbc1369",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_period(df):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function that receives a dataframe that has SST data for different days \n",
    "    and returns a dictionaire of dataframes (one for each different day) (dict_df) and \n",
    "    an array with the different dates its possible to find in our dataframe (specificday)\n",
    "    \"\"\"\n",
    "    \n",
    "    specificday = [pd.Timestamp(dd).strftime(\"%Y-%m-%d %H:%M:%S\") for dd in df['time'].unique()]\n",
    "    specificday = np.array(specificday, dtype=np.object)\n",
    "  \n",
    "    #create a dictionary to store the data frames for each day\n",
    "    dict_df = {elem : pd.DataFrame for elem in specificday}\n",
    "\n",
    "    for key in dict_df.keys():\n",
    "        dict_df[key] = df[:][df['time'] == key]\n",
    "        \n",
    "    return dict_df, specificday\n",
    "\n",
    "#after this function we only have to define the period we want to analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c7f1bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_df_mur_aug, specificday_mur_aug = get_period(df_mur_aug)\n",
    "#dict_df_mur_aug -> dictionaire of dataframes for each day of August 2019 of the MUR data\n",
    "#specificday_mur_aug -> array with all the days of August 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9ec4c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ad9be8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "02505535",
   "metadata": {},
   "source": [
    "## Cayula-Cornillon Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5374d972",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72d64e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFrontInWindow(w, head, minTheta, minPopProp, minPopMeanDiff, minSinglePopCohesion, \n",
    "                     minGlobalPopCohesion, corners):\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    This functions detects fronts in slidding windows. If a front is detected, the function will return\n",
    "    2 1D arrays (x and y) with the coordinate values corresponding to the location of the front.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    #empty arrays de xdata, ydata e z\n",
    "    xdata = np.array([])\n",
    "    ydata = np.array([])\n",
    "    z = np.array([])\n",
    "    exitType=0\n",
    "    \n",
    "    #mask is an array with the same shape of w, that is 1 if in that index position w = np.nan and 0 otherwise\n",
    "    mask = np.isnan(w).astype('int')  \n",
    "    haveNaNs = np.any(mask[:]).astype('int')  #haveNaNs=1 if mask has 1s (that correspond to NaNs in matrix w)\n",
    "    n_NaNs=0\n",
    "    \n",
    "    \n",
    "    if haveNaNs:\n",
    "        n_NaNs = sum(mask.flatten()[:])       # count nr of 1s (NaNs in matrix w) that there are\n",
    "        if (n_NaNs/len(w.flatten())>0.5):     #window can't have more than 50% of its pixels as NaNs\n",
    "            exitType=-1\n",
    "            return None,None,None,exitType  \n",
    "        \n",
    "    mi_ma = [np.nanmin(w), np.nanmax(w)]                          #array with minimum and maximum value of w\n",
    "    n = math.ceil((mi_ma[1]-mi_ma[0])/0.02)                       #number of bins\n",
    "    bins = np.arange(mi_ma[0], mi_ma[1], 0.02)                    #to define the bins sequence \n",
    "    [y, xout] = np.histogram(w[:], bins, mi_ma)                   #y->frequency counts, Xout->bin location\n",
    "    xout = np.mean(np.vstack([xout[0:-1],xout[1:]]), axis=0)     #xout to be relative to the centers of the bins\n",
    "    \n",
    "    \n",
    "    thresValue = xout[0]        \n",
    "    totalCount = len(w.flatten()) - n_NaNs    #nr of non NaN pixels \n",
    "    threshPopACount = 0\n",
    "    threshSeparation = -1\n",
    "    threshPopAMean = 0\n",
    "    threshPopBMean = 0\n",
    "    \n",
    "    w[mask==1] = 0                      #Replace NaNs with 0's (when mask is 1 replace values of array w for 0)\n",
    "    totalSum = sum(w.flatten())                      #sum of values of matrix w\n",
    "    totalSumSquares = sum(w.flatten()*w.flatten())   #sum of the squares of the values of w\n",
    "    \n",
    "    #In this for loop we are going to discover which line is going to make the best separation between the average\n",
    "    # of population on the left and on the right (A and B) - and that is going to be the thresValue\n",
    "    for k in range(1,n-1):     #ignore the first and last candidates (senão seria de 0 a n)\n",
    "        popASum = sum(y[0:k+1] * xout[0:k+1])    \n",
    "        popBSum = sum(y[k+1:] * xout[k+1:])  \n",
    "        popACount = sum(y[0:k+1])     #sum of frequencies (y) from populationA\n",
    "        popBCount = sum(y[k+1:])      #sum of frequencies (y) from populationB\n",
    "    \n",
    "        popAMean = popASum/popACount\n",
    "        try:                                  #to avoid the zerodivisionerror that was poping up \n",
    "            popBMean = popBSum/popBCount\n",
    "        except ZeroDivisionError:\n",
    "            popBMean = 0\n",
    "        separation = popACount * popBCount * (popAMean - popBMean) * (popAMean - popBMean)\n",
    "        if separation>threshSeparation:\n",
    "            threshSeparation = separation\n",
    "            thresValue = xout[k]\n",
    "            threshPopACount = popACount\n",
    "            threshPopAMean = popAMean\n",
    "            threshPopBMean = popBMean\n",
    "            \n",
    "         \n",
    "        #abort in case the proportion of population A is less that a certain minimum\n",
    "    if (threshPopACount / totalCount < minPopProp):\n",
    "        exitType = 1\n",
    "        return None,None, None, exitType  \n",
    "    \n",
    "    #abort in case the proportion of population B is less that a certain minimum\n",
    "    if (1.0 - threshPopACount / totalCount < minPopProp):\n",
    "        exitType = 1\n",
    "        return None,None,None, exitType  \n",
    "    \n",
    "    #abort this window if the difference in the populations means is less than a minimum value\n",
    "    if (threshPopBMean - threshPopAMean < minPopMeanDiff):   \n",
    "        exitType = 2\n",
    "        return None,None,None,exitType  \n",
    "    \n",
    "    #Calculate the criterion function THETA (TAUopt) in page 72 of the paper\n",
    "    totalMean = totalSum/totalCount\n",
    "    variance = totalSumSquares - (totalMean * totalMean * totalCount)\n",
    "    theta = threshSeparation / (variance * totalCount)\n",
    "    if (theta < minTheta):         #abort if theta is lower than a certain minimum  \n",
    "        exitType = 3\n",
    "        return None,None,None,exitType  \n",
    "    \n",
    "#Cohesion - now that we know the separation value. Based on this value we will check the matrix element by \n",
    "#element, and check whether is bigger or lower than the separation  \n",
    "#we check if it's bigger bellow or to the right (when its bigger we add from one side, when its lower add to the other)\n",
    "#Count the nr of times a population A cell is immediately adjacent to another popA cell and the same for popB\n",
    "# A cell can be adjacent on 4 sides. Count only 2 of them (bottom and right side) because doing all 4 would be\n",
    "#redundant. Do not count diagonal neighbors\n",
    "    countANextToA = 0\n",
    "    countBNextToB = 0\n",
    "    countANextToAOrB = 0\n",
    "    countBNextToAOrB = 0\n",
    "    [n_rows, n_cols] = w.shape\n",
    "    for col in range(0, n_cols-1):\n",
    "        for row in range(0, n_rows-1):\n",
    "            if (haveNaNs & (mask[row, col] | mask[row+1, col] | mask[row, col+1])):\n",
    "                continue\n",
    "                         \n",
    "            #examine the bottom neighbor\n",
    "            if (w[row, col] <= thresValue):                  #if matrix pixel < than the element of separation\n",
    "                countANextToAOrB = countANextToAOrB + 1      #increase by 1 countANextToAOrB\n",
    "                if (w[row+1, col] <= thresValue):            #if pixel of bottom row < than separation\n",
    "                    countANextToA = countANextToA + 1        #increase countANextToA\n",
    "            else:                                            #if pixel > than separation \n",
    "                countBNextToAOrB = countBNextToAOrB + 1      #increase countBNextToAOrB\n",
    "                if (w[row+1, col] > thresValue):             #if pixel of bellow row > separation\n",
    "                    countBNextToB = countBNextToB + 1        #increase countBNextToB\n",
    "                         \n",
    "                         \n",
    "            # Examine the right neighbor\n",
    "            if (w[row, col] <= thresValue):                     #if matrix pixel < separation      \n",
    "                countANextToAOrB = countANextToAOrB + 1         # increase countANextToAOrB\n",
    "                if (w[row, col+1] <= thresValue):               #if right pixel < separation\n",
    "                    countANextToA = countANextToA + 1           # increase countANextToA\n",
    "            else:                                               #if matrix pixel > separation\n",
    "                countBNextToAOrB = countBNextToAOrB + 1         #increase countBNextToAOrB\n",
    "                if (w[row, col+1] > thresValue):                #if right pixel > separation\n",
    "                    countBNextToB = countBNextToB +1            # increase countBNextToB\n",
    "                         \n",
    "                         \n",
    "    popACohesion = countANextToA / countANextToAOrB\n",
    "    popBCohesion = countBNextToB/ countBNextToAOrB\n",
    "    globalCohesion = (countANextToA + countBNextToB) / (countANextToAOrB + countBNextToAOrB)\n",
    "    \n",
    "    #These ifs are in case of errors (parameters below certain limits)\n",
    "    if (popACohesion < minSinglePopCohesion):\n",
    "        exitType = 4\n",
    "        return None, None,None,exitType  \n",
    "                         \n",
    "    if (popBCohesion < minSinglePopCohesion):\n",
    "        exitType = 4\n",
    "        return None, None, None,exitType  \n",
    "                         \n",
    "    if (globalCohesion < minGlobalPopCohesion):\n",
    "        exitType = 4\n",
    "        return None, None, None,exitType  \n",
    "                         \n",
    "                         \n",
    "    #OK if we reach here we have a front. Compute its contour\n",
    "    X = np.linspace(head[0], head[1], n_cols)    \n",
    "    Y = np.linspace(head[2], head[3], n_rows)\n",
    "    if (corners.size == 0):\n",
    "        w = w.astype('double')    \n",
    "        if haveNaNs:\n",
    "            w[w==0] = np.nan      # Need to restore the NaNs to not invent new contours around zeros\n",
    "        \n",
    "        c = plt.contour(X, Y, w, [thresValue])    #Create and store a set of contour lines or filled regions.\n",
    "    else:\n",
    "        #the 4 corners have these indices [17,32,17,32; 17,32,1,16; 1,16,1,16;1,16,17,32]\n",
    "        # and the variable corners has one of its rows (the current to be retained sub-window)\n",
    "        \n",
    "        X = X[np.arange(corners[2]-1, corners[3])]\n",
    "        Y = Y[np.arange(corners[0]-1, corners[1])]\n",
    "        w = w[np.arange(corners[0], corners[1]).min()-1:np.arange(corners[0], corners[1]).max()+1, np.arange(corners[2], corners[3]).min()-1:np.arange(corners[2], corners[3]).max()+1]\n",
    "        \n",
    "        if  haveNaNs:\n",
    "            w[w==0] = np.nan     # Need to restore the NaNs to not invent new contours around zeros\n",
    "                         \n",
    "        if (np.isnan(w)).all()==True:\n",
    "            c = np.array([])\n",
    "        else:\n",
    "            c = plt.contour(X, Y, w, [thresValue])     #Create and store a set of contour lines or filled regions.\n",
    "                     \n",
    "                \n",
    "        \n",
    "        M = c.allsegs[:]          #list of arrays for contour c. Each array corresponds to a line that may or may\n",
    "                                    #not be drawn. This list can have any number of arrays\n",
    "            \n",
    "        M = [x for x in M if x]   #if the list has empty arrays we will drop them\n",
    "        \n",
    "        count = 0   #to iterate through the various arrays\n",
    "        \n",
    "        #Create list of booleans (True or False) wether the conditions bellow are fulfilled\n",
    "        # Each array (line of contour) must have more that 7 data points and they can't be closed lines\n",
    "        lista = []     \n",
    "        for i in range(len(M[:])):\n",
    "            lista.append([(len(x)<7 or (x[0][0]==x[-1][0] and x[0][1] == x[-1][1])) for x in M[:][i]])\n",
    "            \n",
    "            #if False the line will be drawn\n",
    "            #if True the line will be ignored\n",
    "            \n",
    "        for value in lista:\n",
    "            if value == [True]:\n",
    "                continue        #return to the top of the for loop\n",
    "            else:\n",
    "        \n",
    "                #For the first array of M we will take all the values of x and put them into an array\n",
    "                x = []\n",
    "                for i in range(len(M[:][count][0])):\n",
    "                    x.append((M[:][count][0][i][0]).round(4))\n",
    "                \n",
    "                #For the first array of M we will take all the values of y and put them into an array\n",
    "                y = []\n",
    "                for i in range(len(M[:][count][0])):\n",
    "                    y.append((M[:][count][0][i][1]).round(4))\n",
    "                \n",
    "                \n",
    "                #save the x and y data points for each line in an xdata and ydata array\n",
    "                xdata = np.append(xdata, x)    \n",
    "                ydata = np.append(ydata, y)\n",
    "        \n",
    "                #each soon to be drawn line is separated by an np.nan value\n",
    "                xdata = np.append(xdata, np.nan)\n",
    "                ydata = np.append(ydata, np.nan)\n",
    "                    \n",
    "                count = count + 1\n",
    "            \n",
    "        \n",
    "        z = thresValue\n",
    "        \n",
    "        if (xdata.size == 0):\n",
    "            exitType = 5;\n",
    "            \n",
    "    return xdata, ydata, z, exitType\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1b2fd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b25126fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CCA_SIED(df):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function applies the Cayula-Cornillon Algorithm Single Image Edge Detector (CCA_SIED) to a single image\n",
    "    df - dataframe in which the CCA_SIED will be applied. This datafram has a column for the longitude,\n",
    "    latitude and SST values. \n",
    "    For a single image, the function return the fronts coordinates (x,y) points \n",
    "    \"\"\"\n",
    "    \n",
    "    #convert the latitude and longitude columns to a numpy array\n",
    "    lat = df['latitude'].to_numpy()\n",
    "    lon = df['longitude'].to_numpy()\n",
    "    \n",
    "    lat = np.unique(lat).round(3)        #get the unique values of the latitude array\n",
    "    lon = np.unique(lon).round(3)        #get the unique values of the longitude array\n",
    "    \n",
    "    #get the sst values as a grid acording to the longitude (nr of rows) and latitude (nr of columns)\n",
    "    sst = df.pivot_table(index='longitude', columns='latitude', values='thetao').values.round(4)\n",
    "    \n",
    "    lat_min = lat.min()     \n",
    "    lat_max = lat.max()\n",
    "    lon_min = lon.min()\n",
    "    lon_max = lon.max()\n",
    "    \n",
    "    extent = [lon_min, lon_max, lat_min, lat_max]   # for visualization in the plt.imshow()\n",
    "\n",
    "    lat_unique = len(np.unique(lat))    # nr of different latitude points\n",
    "    lon_unique = len(np.unique(lon))    #nr of different longitude points\n",
    "\n",
    "    X = np.linspace(lon_min, lon_max, lon_unique)        #linearly spaced vector with the longitude points\n",
    "    Y = np.linspace(lat_min, lat_max, lat_unique)        #linearly spaced vector with the latitude points\n",
    "    X, Y = np.meshgrid(X, Y)                 #create a rectangular grid out of two given one-dimensional arrays\n",
    "\n",
    "    lat, lon = np.meshgrid(lat, lon)            \n",
    "\n",
    "    from scipy.interpolate import griddata\n",
    "    Z = griddata((lon.flatten(), lat.flatten()), sst.flatten(), (X,Y), method='linear')  \n",
    "    \n",
    "    head = np.array([lon_min, lon_max])           #Extremos do array que se obtem com a meshgrid em X\n",
    "    head = np.append(head, [lat_min, lat_max])   #Extremos do array que se obtem com a meshgrid em Y\n",
    "\n",
    "    z_dim = Z.shape    #dimensões da matriz Z (rows, cols)\n",
    "\n",
    "    z_actual_range = np.array([np.nanmin(Z[:]), np.nanmax(Z[:])])    #range dos dados (valor minimo e maximo da matriz Z)\n",
    "    nx = z_dim[1]      # number of columns of matrix Z\n",
    "    ny = z_dim[0]      # number of rows of matrix Z\n",
    "    node_offset = 0\n",
    "    \n",
    "    #index 4 -> menor valor de Z; index5 -> maior valor de Z; index6 -> node_offset=0\n",
    "    head = np.append(head, np.array([z_actual_range[0], z_actual_range[1] , node_offset]))    \n",
    "    head = np.append(head, np.array((head[1]- head[0])/(nx - int(not node_offset))))     #index 7 -> quociente da diferença dos extremos da meshgrid em X e o nr de colunas-1\n",
    "    head = np.append(head, np.array((head[3]- head[2])/(ny - int(not node_offset))))     #index 8 -> quociente da diferença dos extremos da meshgrid em Y e o nr de rows-1\n",
    "    head = head.astype('float')\n",
    "\n",
    "    \n",
    "    #cayula\n",
    "    minPopProp = 0.20        #minimum proportion of each population\n",
    "    minPopMeanDiff = 0.4     # minimum difference between the means of the 2 populations\n",
    "    minTheta = 0.70\n",
    "    minSinglePopCohesion = 0.90\n",
    "    minGlobalPopCohesion = 0.70\n",
    "    \n",
    "    \n",
    "    [n_rows, n_cols] = Z.shape       #nr de rows e nr de columns da matriz Z\n",
    "    winW16 = 16\n",
    "    winW32 = 16*2\n",
    "    winW48 = 16*3\n",
    "\n",
    "\n",
    "    #arrays that will store the contour of every front that will be detected\n",
    "    xdata_final = np.array([])\n",
    "    ydata_final = np.array([])\n",
    "\n",
    "    s=0 #s=1 means subwindows do NOT share a common border. With s = 0 they do.\n",
    "\n",
    "    xSide16 = winW16*head[7]\n",
    "    ySide16 = winW16*head[8]\n",
    "    xSide32 = (winW32 - s) * head[7]\n",
    "    ySide32 = (winW32 - s) * head[8]\n",
    "\n",
    "    nWinRows = math.floor(n_rows/winW16)   #times a window can slide over the rows \n",
    "    nWinCols = math.floor(n_cols/winW16)   #times a window can slide over the columns\n",
    "\n",
    "\n",
    "    for wRow in range(1, nWinRows-1):    \n",
    "        #start and stop indices and coords of current window\n",
    "        r1 = (wRow-1) * winW16 + 1\n",
    "        r2 = r1 + winW48 -s     \n",
    "    \n",
    "        y0 = head[2] + (wRow-1)*ySide16    \n",
    "    \n",
    "        for wCol in range(1, nWinCols-1):     \n",
    "            c1 = (wCol - 1)*winW16+1\n",
    "            c2 = c1 + winW48 - s\n",
    "            x0 = head[0] + (wCol-1) * xSide16     \n",
    "            wPad = Z[r1-1:r2, c1-1:c2]            # 49x49 (or 48x48 if s == 1) Window\n",
    "        \n",
    "            rr = np.array([1,1,2,2])\n",
    "            cc = np.array([1,2,2,1])\n",
    "        \n",
    "            if s==1:\n",
    "                corners = np.array([[17, 32, 17, 32], [17, 32, 1, 16], [1, 16, 1, 16], [1, 16, 17, 32]])  #less good\n",
    "            else:\n",
    "                corners = np.array([[17, 33, 17, 33], [17, 33, 1, 17], [1, 17, 1, 17], [1, 17, 17, 33]])\n",
    "            \n",
    "            for k in range(0,4):     #loop over the 4 slidding 32X32 sub-windows of the larger 48x48 one\n",
    "                m1 = (rr[k] - 1) * winW16 + 1\n",
    "                m2 = m1 + 2 * winW16 - s             #indices of the slidding 33X33 window\n",
    "                n1 = (cc[k] - 1) * winW16 + 1\n",
    "                n2 = n1 + 2 * winW16 - s\n",
    "            \n",
    "                w = wPad[m1-1:m2, n1-1:n2].astype('double')      #sub window with size 33x33\n",
    "            \n",
    "                #corners coordinates\n",
    "                subWinX0 = x0 + (cc[k] - 1) * xSide16\n",
    "                subWinX1 = subWinX0 + xSide32\n",
    "                subWinY0 = y0 + (rr[k] - 1) * ySide16\n",
    "                subWinY1 = subWinY0 + ySide32\n",
    "            \n",
    "                R = np.array([subWinX0, subWinX1, subWinY0, subWinY1])\n",
    "          \n",
    "                xdata, ydata, z, exitType = getFrontInWindow(w, R, minTheta, minPopProp, minPopMeanDiff, minSinglePopCohesion, minGlobalPopCohesion, corners[k,:])\n",
    "            \n",
    "                if (exitType == 0):\n",
    "                   \n",
    "                    xdata_final = np.append(xdata_final, xdata)\n",
    "                \n",
    "                    ydata_final = np.append(ydata_final,ydata)\n",
    "    \n",
    "    \n",
    "    return xdata_final, ydata_final\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad56b81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8763f686",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0444d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CCA_front_visualization_mur(df): \n",
    "    \n",
    "    \"\"\"\n",
    "    This function receives a dataframe with MUR data for a individual day and plots the result\n",
    "    of the aplication of the Cayula-Cornillon Algorithm\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    front = np.zeros((1001,1401))       #initialize a matrix of zeros. This shape is for the MUR data\n",
    "        \n",
    "    xdata_final, ydata_final = CCA_SIED(df)       \n",
    "    \n",
    "    cols_x = np.array([])\n",
    "    for value in xdata_final:                     #convert values in array x to the respective index in a (1001, 1401) matrix\n",
    "        aux_x = (19+value)/0.01                  #these numbers are relative to the MUR data\n",
    "        cols_x = np.append(cols_x, aux_x)\n",
    "    \n",
    "    rows_y = np.array([])\n",
    "    for value in ydata_final:                     #convert values in array y to the respective index in a (1001, 1401) matrix\n",
    "        aux_y = (45-value)/0.01                  #these numbers are relative to the MUR data\n",
    "        rows_y = np.append(rows_y, aux_y)\n",
    "\n",
    "    cols_x = np.round(cols_x)\n",
    "    rows_y = np.round(rows_y)\n",
    "            \n",
    "    for i in range(len(cols_x)):   #it could also be len(rows_y)\n",
    "        front[int(rows_y[i]), int(cols_x[i])] = front[int(rows_y[i]), int(cols_x[i])] + 1\n",
    "        \n",
    "    front[front != 0] = 1\n",
    "    \n",
    "    \n",
    "    #Create a masked_array in order to get the continental zone well defined\n",
    "    \n",
    "    #Convert some df to a numpy array with the SST values for each value of longitude and latitude\n",
    "    sst = df.pivot_table(index='longitude', columns='latitude', values='thetao').T.values   \n",
    "    mask = np.isnan(np.flipud(sst))       #Boolean array=True where array Temp had Null values (continental zone)\n",
    "    mask255 =np.where(mask,(np.ones(mask.shape))*255,0).astype(\"uint8\")   #array which pixels = 255 when mask=True \n",
    "    #Make a dilation to ensure the pixels that belong to the shore are not consideredd fronts\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    mask_dilated = cv2.dilate(mask255, kernel)\n",
    "    front = np.ma.masked_where(mask_dilated==255, front)   \n",
    "    \n",
    "    \n",
    "    lat = np.array(df['latitude'].unique())\n",
    "    lon = np.array(df['longitude'].unique())\n",
    "    lat = np.unique(lat).round(3)\n",
    "    lon = np.unique(lon).round(3)\n",
    "    \n",
    "    #Visualization purposes: continenal area in gray, and pixels with value=0 in white   \n",
    "    viridis = matplotlib.cm.get_cmap('viridis', 30)\n",
    "    newcolor = viridis(np.linspace(0,1,30))\n",
    "    white = np.array([1, 1, 1, 1])\n",
    "    newcolor[0, :] = white\n",
    "    newcmp = ListedColormap(newcolor)\n",
    "    newcmp.set_bad(color='gray')\n",
    "    \n",
    "    \n",
    "    plt.imshow(front, cmap=newcmp, extent = [lon[0], lon[-1], lat[0], lat[-1]])    \n",
    "    #extent is to define the extention of the x and y axis\n",
    "    plt.title(\"Cayula-Cornillon Algorithm 15th June 2022 (MUR)\", fontsize=20)\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd28e72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f872d10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd20dc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
