{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59d598f3",
   "metadata": {},
   "source": [
    "Em vez de estar sempre a usar os thresholds de 90/180, usar um slider. Por exemplo quando o slider esta nos 45, ele vai fazer o processamento todo (o pipeline todo) para me dar a imagem que em vez de ser com thresholds de 90/180, seja com 45/90. \n",
    "\n",
    "Tenho que começar a agrupar isto por funções, de maneira a que qnd altero o 1º parametro, tem-se um input e esse input vai fazer com que a imagem do canny vá mudar e vamos correr o algoritmo para as imagens em questão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b9a8b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e52b80d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import netCDF4 as nc\n",
    "import cv2\n",
    "import datetime\n",
    "import xarray as xr\n",
    "import os\n",
    "plt.rcParams[\"figure.figsize\"] = 10, 8\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b667c8f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832fdc4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "350a6dc7",
   "metadata": {},
   "source": [
    "### Importação dos dados de Atlantic-Iberian Biscay Irish- Ocean Physics Reanalysis\n",
    "\n",
    "Importar o ficheiro netCDF da pasta data do repositório e depois converte-lo para o formato de dataframa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "45cb6d40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/luisfigueiredo/JUNO/notebooks'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_path = os.getcwd()\n",
    "current_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d20f04b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/luisfigueiredo/JUNO/notebooks/../data'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "data_folder = os.path.join(current_path,\"../data\")\n",
    "data_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b5543a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_path = os.path.join(data_folder, \"IBI2014-2019.nc\")\n",
    "ds = nc.Dataset(nc_path)\n",
    "data = xr.load_dataset(nc_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c3c171e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'netCDF4._netCDF4.Dataset'>\n",
      "root group (NETCDF4 data model, file format HDF5):\n",
      "    Conventions: CF-1.0\n",
      "    source: CMEMS IBI-MFC\n",
      "    institution: Puertos del Estado (PdE) - Mercator-Ocean (MO)\n",
      "    references: http://marine.copernicus.eu\n",
      "    title: CMEMS IBI REANALYSIS: DAILY PHYSICAL PRODUCTS \n",
      "    easting: longitude\n",
      "    northing: latitude\n",
      "    domain_name: IBI12\n",
      "    FROM_ORIGINAL_FILE__field_type: mean\n",
      "    field_date: 20191224\n",
      "    FROM_ORIGINAL_FILE__longitude_min: -19.f\n",
      "    FROM_ORIGINAL_FILE__longitude_max: 5.f\n",
      "    FROM_ORIGINAL_FILE__latitude_min: 26.f\n",
      "    FROM_ORIGINAL_FILE__latitude_max: 56.f\n",
      "    z_min: 0.50576f\n",
      "    z_max: 5698.061f\n",
      "    contact: mailto: servicedesk.cmems@mercator-ocean.eu\n",
      "    bulletin_date: 2020-12-01\n",
      "    bulletin_type: Reanalysis\n",
      "    _CoordSysBuilder: ucar.nc2.dataset.conv.CF1Convention\n",
      "    comment: \n",
      "    history: Data extracted from dataset http://localhost:8080/thredds/dodsC/cmems_mod_ibi_phy_my_0.083deg-3D_P1D-m\n",
      "    dimensions(sizes): depth(1), latitude(121), time(2184), longitude(169)\n",
      "    variables(dimensions): float32 depth(depth), float32 latitude(latitude), int16 thetao(time, depth, latitude, longitude), int64 time(time), float32 longitude(longitude)\n",
      "    groups: \n"
     ]
    }
   ],
   "source": [
    "print(ds)     # informações relativas ao ficheiro netCDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "00ed503d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converter o ficheiro netCDF para uma dataframe\n",
    "datadf = data.to_dataframe()\n",
    "df2014_2019 = datadf.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0dc55e16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>time</th>\n",
       "      <th>thetao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35.0</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>2014-01-01 12:00:00</td>\n",
       "      <td>18.316000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35.0</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>2014-01-02 12:00:00</td>\n",
       "      <td>18.309000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35.0</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>2014-01-03 12:00:00</td>\n",
       "      <td>18.316000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>2014-01-04 12:00:00</td>\n",
       "      <td>18.273001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>2014-01-05 12:00:00</td>\n",
       "      <td>18.230000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44660611</th>\n",
       "      <td>45.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>2019-12-20 12:00:00</td>\n",
       "      <td>13.619000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44660612</th>\n",
       "      <td>45.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>2019-12-21 12:00:00</td>\n",
       "      <td>13.559000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44660613</th>\n",
       "      <td>45.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>2019-12-22 12:00:00</td>\n",
       "      <td>13.458000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44660614</th>\n",
       "      <td>45.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>2019-12-23 12:00:00</td>\n",
       "      <td>13.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44660615</th>\n",
       "      <td>45.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>2019-12-24 12:00:00</td>\n",
       "      <td>13.390000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44660616 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          latitude  longitude                time     thetao\n",
       "0             35.0      -19.0 2014-01-01 12:00:00  18.316000\n",
       "1             35.0      -19.0 2014-01-02 12:00:00  18.309000\n",
       "2             35.0      -19.0 2014-01-03 12:00:00  18.316000\n",
       "3             35.0      -19.0 2014-01-04 12:00:00  18.273001\n",
       "4             35.0      -19.0 2014-01-05 12:00:00  18.230000\n",
       "...            ...        ...                 ...        ...\n",
       "44660611      45.0       -5.0 2019-12-20 12:00:00  13.619000\n",
       "44660612      45.0       -5.0 2019-12-21 12:00:00  13.559000\n",
       "44660613      45.0       -5.0 2019-12-22 12:00:00  13.458000\n",
       "44660614      45.0       -5.0 2019-12-23 12:00:00  13.400000\n",
       "44660615      45.0       -5.0 2019-12-24 12:00:00  13.390000\n",
       "\n",
       "[44660616 rows x 4 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2014_2019 = df2014_2019.drop(['depth'], axis=1)     #dropar coluna 'depth' (não é necessária pq é sempre igual)\n",
    "df2014_2019   #os dados .nc estão agora no formato de uma dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a282f148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>thetao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-01-01 12:00:00</td>\n",
       "      <td>35.0</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>18.316000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-01-02 12:00:00</td>\n",
       "      <td>35.0</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>18.309000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-01-03 12:00:00</td>\n",
       "      <td>35.0</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>18.316000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-01-04 12:00:00</td>\n",
       "      <td>35.0</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>18.273001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-01-05 12:00:00</td>\n",
       "      <td>35.0</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>18.230000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44660611</th>\n",
       "      <td>2019-12-20 12:00:00</td>\n",
       "      <td>45.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>13.619000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44660612</th>\n",
       "      <td>2019-12-21 12:00:00</td>\n",
       "      <td>45.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>13.559000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44660613</th>\n",
       "      <td>2019-12-22 12:00:00</td>\n",
       "      <td>45.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>13.458000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44660614</th>\n",
       "      <td>2019-12-23 12:00:00</td>\n",
       "      <td>45.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>13.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44660615</th>\n",
       "      <td>2019-12-24 12:00:00</td>\n",
       "      <td>45.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>13.390000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44660616 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        time  latitude  longitude     thetao\n",
       "0        2014-01-01 12:00:00      35.0      -19.0  18.316000\n",
       "1        2014-01-02 12:00:00      35.0      -19.0  18.309000\n",
       "2        2014-01-03 12:00:00      35.0      -19.0  18.316000\n",
       "3        2014-01-04 12:00:00      35.0      -19.0  18.273001\n",
       "4        2014-01-05 12:00:00      35.0      -19.0  18.230000\n",
       "...                      ...       ...        ...        ...\n",
       "44660611 2019-12-20 12:00:00      45.0       -5.0  13.619000\n",
       "44660612 2019-12-21 12:00:00      45.0       -5.0  13.559000\n",
       "44660613 2019-12-22 12:00:00      45.0       -5.0  13.458000\n",
       "44660614 2019-12-23 12:00:00      45.0       -5.0  13.400000\n",
       "44660615 2019-12-24 12:00:00      45.0       -5.0  13.390000\n",
       "\n",
       "[44660616 rows x 4 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2014_2019 = df2014_2019[['time', 'latitude', 'longitude', 'thetao']]    #reorganizar as colunas da dataframe\n",
    "df2014_2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b689ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar esta df no nosso repositorio nao e grande ideia porque ocupa 2,5GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a94b70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb671ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c389e1d",
   "metadata": {},
   "source": [
    "### Gerar array com os dias para os quais quero depois aplicar o canny\n",
    "\n",
    "É criado o dicionário days que tem muitas dataframes e depois dá para aceder a estas df individualmente com os valores do array que são extraidos através do specific day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "91c73455",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataf2014_2019 = df2014_2019.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "dbb74a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "specificday = [pd.Timestamp(dd).strftime(\"%Y-%m-%d %H:%M:%S\") for dd in dataf2014_2019['time'].unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1fb497c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "specificday = np.array(specificday, dtype=np.object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1327236a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2014-01-01 12:00:00', '2014-01-02 12:00:00',\n",
       "       '2014-01-03 12:00:00', ..., '2019-12-22 12:00:00',\n",
       "       '2019-12-23 12:00:00', '2019-12-24 12:00:00'], dtype=object)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "specificday  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8e501cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dictionary to store the data frames for each day\n",
    "days = {elem : pd.DataFrame for elem in specificday}\n",
    "\n",
    "for key in df.keys():\n",
    "    days[key] = dataf2014_2019[:][dataf2014_2019['time'] == key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1beea4de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2014-10-01 12:00:00', '2014-10-02 12:00:00',\n",
       "       '2014-10-03 12:00:00', '2014-10-04 12:00:00',\n",
       "       '2014-10-05 12:00:00', '2014-10-06 12:00:00',\n",
       "       '2014-10-07 12:00:00', '2014-10-08 12:00:00',\n",
       "       '2014-10-09 12:00:00', '2014-10-10 12:00:00',\n",
       "       '2014-10-11 12:00:00', '2014-10-12 12:00:00',\n",
       "       '2014-10-13 12:00:00', '2014-10-14 12:00:00',\n",
       "       '2014-10-15 12:00:00', '2014-10-16 12:00:00',\n",
       "       '2014-10-17 12:00:00', '2014-10-18 12:00:00',\n",
       "       '2014-10-19 12:00:00', '2014-10-20 12:00:00',\n",
       "       '2014-10-21 12:00:00', '2014-10-22 12:00:00',\n",
       "       '2014-10-23 12:00:00', '2014-10-24 12:00:00',\n",
       "       '2014-10-25 12:00:00', '2014-10-26 12:00:00',\n",
       "       '2014-10-27 12:00:00', '2014-10-28 12:00:00',\n",
       "       '2014-10-29 12:00:00', '2014-10-30 12:00:00',\n",
       "       '2014-10-31 12:00:00', '2014-11-01 12:00:00',\n",
       "       '2014-11-02 12:00:00', '2014-11-03 12:00:00',\n",
       "       '2014-11-04 12:00:00', '2014-11-05 12:00:00',\n",
       "       '2014-11-06 12:00:00', '2014-11-07 12:00:00',\n",
       "       '2014-11-08 12:00:00', '2014-11-09 12:00:00',\n",
       "       '2014-11-10 12:00:00', '2014-11-11 12:00:00',\n",
       "       '2014-11-12 12:00:00', '2014-11-13 12:00:00',\n",
       "       '2014-11-14 12:00:00', '2014-11-15 12:00:00',\n",
       "       '2014-11-16 12:00:00', '2014-11-17 12:00:00',\n",
       "       '2014-11-18 12:00:00', '2014-11-19 12:00:00',\n",
       "       '2014-11-20 12:00:00', '2014-11-21 12:00:00',\n",
       "       '2014-11-22 12:00:00', '2014-11-23 12:00:00',\n",
       "       '2014-11-24 12:00:00', '2014-11-25 12:00:00',\n",
       "       '2014-11-26 12:00:00', '2014-11-27 12:00:00',\n",
       "       '2014-11-28 12:00:00', '2014-11-29 12:00:00',\n",
       "       '2014-11-30 12:00:00', '2014-12-01 12:00:00',\n",
       "       '2014-12-02 12:00:00', '2014-12-03 12:00:00',\n",
       "       '2014-12-04 12:00:00', '2014-12-05 12:00:00',\n",
       "       '2014-12-06 12:00:00', '2014-12-07 12:00:00',\n",
       "       '2014-12-08 12:00:00', '2014-12-09 12:00:00',\n",
       "       '2014-12-10 12:00:00', '2014-12-11 12:00:00',\n",
       "       '2014-12-12 12:00:00', '2014-12-13 12:00:00',\n",
       "       '2014-12-14 12:00:00', '2014-12-15 12:00:00',\n",
       "       '2014-12-16 12:00:00', '2014-12-17 12:00:00',\n",
       "       '2014-12-18 12:00:00', '2014-12-19 12:00:00',\n",
       "       '2014-12-20 12:00:00', '2014-12-21 12:00:00',\n",
       "       '2014-12-22 12:00:00', '2014-12-23 12:00:00',\n",
       "       '2014-12-24 12:00:00', '2014-12-25 12:00:00',\n",
       "       '2014-12-26 12:00:00', '2014-12-27 12:00:00',\n",
       "       '2014-12-28 12:00:00', '2014-12-29 12:00:00',\n",
       "       '2014-12-30 12:00:00', '2014-12-31 12:00:00'], dtype=object)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ond2014 = specificday[(specificday>='2014-10-01 12:00:00') & (specificday <= '2014-12-31 12:00:00')]#+(specificday>='2015-10-01 12:00:00') & (specificday <= '2015-12-31 12:00:00') + (specificday>='2016-10-01 12:00:00') & (specificday <= '2016-12-31 12:00:00') + (specificday>='2017-10-01 12:00:00') & (specificday <= '2017-12-31 12:00:00') + (specificday>='2018-10-01 12:00:00') & (specificday <= '2018-12-31 12:00:00') + (specificday>='2019-10-01 12:00:00') & (specificday <= '2019-12-31 12:00:00')]\n",
    "ond2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474c5694",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9d0b103",
   "metadata": {},
   "source": [
    "### Definir funções para todo o pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c776f084",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ad17f1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def canny_creation(days, Tmax):\n",
    "    \n",
    "    \"\"\"\n",
    "    Função que pega numa df com temperaturas relativas a um certo dia e retorna a matriz obtida através do Canny\n",
    "    com a mask aplicada\n",
    "    \"\"\"\n",
    "    \n",
    "    #Pegar na df dum dia e converte-la num np array com os valores de Temperatura para os valores de long e lati\n",
    "    Temp = days.pivot_table(index='longitude', columns='latitude', values='thetao').T.values\n",
    "    \n",
    "    #Converter os valores de temperatura no formato uint8 com valores entre 0-255\n",
    "    Temp_day = ((Temp - np.nanmin(Temp)) * (1/(np.nanmax(Temp) - np.nanmin(Temp)) * 255)).astype('uint8')\n",
    "\n",
    "    Temp_day = np.flipud(Temp_day)   #flipud -> Reverse the order of elements along axis 0 (up/down).\n",
    "    \n",
    "    #apply the canny algorithm and plot the image with the edges\n",
    "    canny = cv2.Canny(Temp_day, Tmax/2, Tmax, L2gradient=False, apertureSize=3)\n",
    "    \n",
    "    mask = np.isnan(np.flipud(Temp))    #Boolean array é True onde o array original (Temp) tinha valores Nan\n",
    "    mask255 =np.where(mask,(np.ones(mask.shape))*255,0).astype(\"uint8\")   #array cujos pixels= 255 quando mask=True\n",
    "    #Fazer uma dilatação para assegurar que os pixeis que pertencem à costa não são considerados como frentes no canny\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    mask_dilated = cv2.dilate(mask255, kernel)\n",
    "    canny =np.ma.masked_where(mask_dilated==255, canny)\n",
    "    \n",
    "    return canny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98473796",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "847a684b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FrontalProb(period, Tmax):\n",
    "    \"\"\"\n",
    "    Função que retorna um array de shape (121, 169) com a frontal probability de cada pixel\n",
    "    \"\"\"\n",
    "    fp = np.zeros((121,169))\n",
    "    for day in period:\n",
    "        fp = fp + canny_creation(days[day], Tmax)\n",
    "    fp = fp/(len(period)*255)*100\n",
    "    \n",
    "    return fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f5f98a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6e923981",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualization(Tmax):\n",
    "    \n",
    "    \"\"\"\n",
    "    Função para visualizar o map of frontal probability e um histograma com as frontal probabilities\n",
    "    \"\"\"\n",
    "    \n",
    "    fp = FrontalProb(period=ond2014, Tmax=Tmax)\n",
    "    \n",
    "    plt.rcParams[\"figure.figsize\"] = 16, 12\n",
    "    fig = plt.figure()\n",
    "    ax1 = fig.add_subplot(2,2,1)\n",
    "    img = ax1.imshow(fp) \n",
    "    plt.colorbar(img, orientation='horizontal', fraction=0.025, pad=0.08, aspect=50)\n",
    "    plt.title(\"Map of frontal probability for certain period\", fontsize=15)\n",
    "\n",
    "    ax2 = fig.add_subplot(2,2,2)\n",
    "    ax2.hist(fp.flatten(), bins=100);\n",
    "    plt.xlabel('Frontal Probability',fontsize=10)\n",
    "    plt.ylim([0, 2000]);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8572bc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "eaf0dbc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad2f55a74bb44842b0ae1dc8ed78527e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=125, description='Tmax', max=250, min=1), Output()), _dom_classes=('widg…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Utilizar widgets (sliders) para ver diferentes visualizações conforme o threshold\n",
    "import ipywidgets\n",
    "\n",
    "fp = ipywidgets.interact(visualization, Tmax=(1, 250))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e25383f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d45bac8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e86107c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b4d53c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
